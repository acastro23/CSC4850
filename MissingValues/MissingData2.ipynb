{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0             1         2         3         4             5             6         7             8             9             10        11            12            13        14        15  \\\n",
      "0  6.887280e-01 -2.127199e-01  0.498783  0.836527  0.753066 -2.126668e-01  9.427240e-01 -0.452367 -7.710111e-02  1.000000e+99  1.000000e+99  0.612123  7.803668e-02  6.166293e-02 -0.080118  0.206314   \n",
      "1  1.000000e+99  1.102416e-01 -0.219114 -0.007928 -0.126895  3.124277e-01  2.054785e-01  0.228858  1.000000e+99  1.524070e-01 -1.246021e-01 -0.134936  1.000000e+99 -4.521916e-01 -0.526221  0.003796   \n",
      "2 -7.389290e-01 -1.099149e-01 -0.584726  0.184901 -0.124804 -1.822229e-01  1.069205e-01 -0.280529  1.000000e+99 -3.794978e-01 -4.406905e-01 -0.346389  5.204105e-01 -2.457859e-01 -0.101673 -0.029700   \n",
      "3  2.455752e-01 -7.399092e-02 -0.317213 -0.238237 -0.234355 -4.551269e-01 -3.268785e-01 -0.493662 -1.230997e-01 -3.809401e-01 -2.760249e-01 -0.004638 -5.239579e-01  1.000000e+99 -0.278308 -0.173673   \n",
      "4  2.395104e-01  1.000000e+99  0.283365  0.047755  0.235801  1.000000e+99  1.000000e+99 -0.216095 -2.471665e-01  1.670562e-01  1.303969e-01  0.084706  4.246984e-01  6.308938e-02 -0.170065  0.305687   \n",
      "\n",
      "             16            17        18        19            20            21        22        23        24            25        26        27        28            29        30        31  \\\n",
      "0  2.867487e-01  5.206254e-01  0.018280 -0.116924  7.097176e-02  1.000000e+99  0.174303 -0.031218  0.566826  3.731229e-01  0.188858  0.540935  0.289398 -7.308559e-02  0.255052  0.488049   \n",
      "1  1.043623e-01  2.498233e-01  0.216620  0.056263  1.000000e+99 -5.289404e-02 -0.022956 -0.337357  0.698501 -1.617279e-01 -0.441653  0.558558 -0.206270 -1.776117e-01  0.192632 -0.401650   \n",
      "2  1.000000e+99  6.526913e-03 -0.169576 -0.355800 -8.584918e-02 -1.178739e-01 -0.284462 -0.183477 -0.526634  1.000000e+99 -0.285182 -0.464429 -0.434753 -6.720503e-01  0.099290 -0.081124   \n",
      "3 -7.621756e-02 -1.877913e-01 -0.282026 -0.272818 -1.890666e-01  6.595302e-02 -0.170556 -0.096963 -0.273798  1.000000e+99 -0.248478 -0.213817 -0.804595  1.000000e+99  0.106822  0.049958   \n",
      "4  1.000000e+99  1.000000e+99  0.008065  0.171140  2.741177e-01 -8.084995e-02  0.129839  0.089432  0.650487  5.893382e-01 -0.007473  0.585618  0.484521 -1.263347e-01  0.335944  0.372001   \n",
      "\n",
      "             32        33        34            35            36        37        38            39        40        41        42        43            44            45        46            47  \\\n",
      "0  8.151400e-04  0.586743  0.316733  3.355057e-01  3.664570e-02  0.208774  0.593726  5.315638e-01  0.179593  0.694768  0.617762 -0.040676  6.780754e-02  3.274521e-02  0.701679  2.728153e-01   \n",
      "1 -5.674276e-01 -0.200878 -0.201951  1.000000e+99 -3.041667e-01 -0.135100 -0.030054 -2.939853e-02 -0.231804 -0.004617 -0.483945 -0.056103 -3.241404e-01 -1.524204e-01 -0.259235 -1.520412e-01   \n",
      "2  5.381649e-02 -0.154154 -0.227913 -4.641950e-02  9.046206e-02 -0.238265 -0.587547 -9.487115e-01 -0.278944 -0.178492 -0.109231 -0.030136 -2.762238e-01  1.000000e+99 -0.222567  1.000000e+99   \n",
      "3  2.858719e-01  0.174486  0.065479 -9.816572e-02  1.807306e-01 -0.145039  0.062678 -1.197327e-01  0.353774  0.285639  0.233876  0.088700 -2.583937e-02 -3.225317e-01  0.433586  3.236030e-01   \n",
      "4  1.000000e+99  0.437801  0.289657  1.941168e-01  1.000000e+99  0.202369  0.454523  1.000000e+99  0.237784  0.439557 -0.006479 -0.157518  1.000000e+99  6.308964e-02  0.761268  3.216442e-01   \n",
      "\n",
      "         48            49  \n",
      "0  0.242996  4.460160e-02  \n",
      "1 -0.487165 -6.009698e-01  \n",
      "2 -0.180418  1.000000e+99  \n",
      "3  0.360877  2.369610e-01  \n",
      "4  0.199316 -2.375341e-02  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import export_text, plot_tree\n",
    "\n",
    "MissingData2Path = \"../DataFiles/MissingData2.txt\"\n",
    "missing_data2 = pd.read_csv(MissingData2Path, sep=r'\\s+', header=None)\n",
    "\n",
    "# Display options for debugging\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(missing_data2.head())\n",
    "\n",
    "missing_data2.replace(1.00000000000000e+99, np.nan, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_imputation(dataframe, visualize=False):\n",
    "    data = dataframe.copy()\n",
    "    model = DecisionTreeRegressor()\n",
    "    \n",
    "    for col in data.columns[data.isnull().any()]:  # Iterate only through columns with missing values\n",
    "        X = data.drop(columns=[col])  # Features\n",
    "        y = data[col]  # Target\n",
    "        \n",
    "        # Separate rows with and without missing values\n",
    "        X_train, y_train = X[~y.isnull()], y[~y.isnull()]\n",
    "        X_missing = X[y.isnull()]\n",
    "        \n",
    "        # Train the Decision Tree Regressor\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        if visualize:\n",
    "            # Print the decision tree rules\n",
    "            tree_rules = export_text(model, feature_names=X.columns.astype(str))\n",
    "            print(f\"Decision Tree for column {col}:\\n\")\n",
    "            print(tree_rules)\n",
    "            \n",
    "            # Visualize the tree\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plot_tree(model, feature_names=X.columns, filled=True, rounded=True)\n",
    "            plt.title(f\"Decision Tree for column {col}\")\n",
    "            plt.show()\n",
    "        \n",
    "        # Predict and fill missing values\n",
    "        data.loc[y.isnull(), col] = model.predict(X_missing)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data 2 (AFTER)\n",
      "     0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15    16    17    18    19    20    21    22    23    24    25    26    27    28    29    30    31  \\\n",
      "0  0.69 -0.21  0.50  0.84  0.75 -0.21  0.94 -0.45 -0.08  0.17  0.02  0.61  0.08  0.06 -0.08  0.21  0.29  0.52  0.02 -0.12  0.07  0.01  0.17 -0.03  0.57  0.37  0.19  0.54  0.29 -0.07  0.26  0.49   \n",
      "1  0.00  0.11 -0.22 -0.01 -0.13  0.31  0.21  0.23  0.27  0.15 -0.12 -0.13  0.33 -0.45 -0.53  0.00  0.10  0.25  0.22  0.06  0.13 -0.05 -0.02 -0.34  0.70 -0.16 -0.44  0.56 -0.21 -0.18  0.19 -0.40   \n",
      "2 -0.74 -0.11 -0.58  0.18 -0.12 -0.18  0.11 -0.28  0.27 -0.38 -0.44 -0.35  0.52 -0.25 -0.10 -0.03  0.15  0.01 -0.17 -0.36 -0.09 -0.12 -0.28 -0.18 -0.53  0.16 -0.29 -0.46 -0.43 -0.67  0.10 -0.08   \n",
      "3  0.25 -0.07 -0.32 -0.24 -0.23 -0.46 -0.33 -0.49 -0.12 -0.38 -0.28 -0.00 -0.52 -0.15 -0.28 -0.17 -0.08 -0.19 -0.28 -0.27 -0.19  0.07 -0.17 -0.10 -0.27  0.16 -0.25 -0.21 -0.80 -0.06  0.11  0.05   \n",
      "4  0.24  0.04  0.28  0.05  0.24  0.01  0.40 -0.22 -0.25  0.17  0.13  0.08  0.42  0.06 -0.17  0.31  0.15  0.16  0.01  0.17  0.27 -0.08  0.13  0.09  0.65  0.59 -0.01  0.59  0.48 -0.13  0.34  0.37   \n",
      "\n",
      "     32    33    34    35    36    37    38    39    40    41    42    43    44    45    46    47    48    49  \n",
      "0  0.00  0.59  0.32  0.34  0.04  0.21  0.59  0.53  0.18  0.69  0.62 -0.04  0.07  0.03  0.70  0.27  0.24  0.04  \n",
      "1 -0.57 -0.20 -0.20 -0.01 -0.30 -0.14 -0.03 -0.03 -0.23 -0.00 -0.48 -0.06 -0.32 -0.15 -0.26 -0.15 -0.49 -0.60  \n",
      "2  0.05 -0.15 -0.23 -0.05  0.09 -0.24 -0.59 -0.95 -0.28 -0.18 -0.11 -0.03 -0.28 -0.16 -0.22  0.02 -0.18 -0.25  \n",
      "3  0.29  0.17  0.07 -0.10  0.18 -0.15  0.06 -0.12  0.35  0.29  0.23  0.09 -0.03 -0.32  0.43  0.32  0.36  0.24  \n",
      "4 -0.20  0.44  0.29  0.19 -0.15  0.20  0.45  0.00  0.24  0.44 -0.01 -0.16 -0.15  0.06  0.76  0.32  0.20 -0.02  \n"
     ]
    }
   ],
   "source": [
    "# Initial mean imputation to handle NaNs temporarily\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = pd.DataFrame(mean_imputer.fit_transform(missing_data2), columns=missing_data2.columns)\n",
    "\n",
    "# Perform supervised learning-based imputation\n",
    "filled_data = supervised_imputation(data_imputed).round(2)\n",
    "print(\"Missing Data 2 (AFTER)\")\n",
    "print(filled_data.head())\n",
    "\n",
    "output_path = \"../PredictionResults/MissingResults2.txt\"\n",
    "filled_data.to_csv(output_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Imputation with a Decision Tree is a good choice for Dataset 2 because:\n",
    "\n",
    "- **Finds Patterns:** learns how features are connected to predict missing values in the genes and samples\n",
    "- **Customized for Each Feature:** adjusts predictions based on the data\n",
    "- **Works Well for 10% Missing Data:** handles moderate gaps effectively"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
