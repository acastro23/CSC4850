{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.stats import mode\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "trainData = pd.read_csv('TrainData5.txt', sep='\\s+', header=None)\n",
        "trainLabels = pd.read_csv('TrainLabel5.txt', sep='\\s+', header=None)\n",
        "testData = pd.read_csv('TestData5.txt', sep='\\s+', header=None)\n",
        "\n",
        "trainData.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "testData.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
        "\n",
        "missing_count = trainData.isnull().sum()\n",
        "print(f\"Missing values count in train data:\\n{missing_count}\")\n",
        "\n",
        "myScaler = StandardScaler()\n",
        "trainDataScaled = pd.DataFrame(myScaler.fit_transform(trainData), columns=trainData.columns)\n",
        "testDataScaled = pd.DataFrame(myScaler.transform(testData), columns=testData.columns)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(trainDataScaled, trainLabels, shuffle=True, test_size=0.2, random_state=50)\n",
        "\n",
        "myKNN = KNeighborsClassifier(n_neighbors=5)\n",
        "myNN = MLPClassifier(hidden_layer_sizes=(100,), max_iter=5000, learning_rate_init=0.001, early_stopping=True, random_state=50)\n",
        "myDT = DecisionTreeClassifier(random_state=50)\n",
        "\n",
        "myKNN.fit(X_train, y_train.values.ravel())\n",
        "X_valPredictionKNN = myKNN.predict(X_val)\n",
        "\n",
        "myNN.fit(X_train, y_train.values.ravel())\n",
        "X_valPredictionNN = myNN.predict(X_val)\n",
        "\n",
        "myDT.fit(X_train, y_train.values.ravel())\n",
        "X_valPredictionDT = myDT.predict(X_val)\n",
        "\n",
        "X_valAccuracyKNN = accuracy_score(y_val, X_valPredictionKNN)\n",
        "X_valAccuracyNN = accuracy_score(y_val, X_valPredictionNN)\n",
        "X_valAccuracyDT = accuracy_score(y_val, X_valPredictionDT)\n",
        "\n",
        "X_valReportKNN = classification_report(y_val, X_valPredictionKNN, zero_division=1)\n",
        "X_valReportNN = classification_report(y_val, X_valPredictionNN, zero_division=1)\n",
        "X_valReportDT = classification_report(y_val, X_valPredictionDT, zero_division=1)\n",
        "\n",
        "print(f\"The validation set had an accuracy of {X_valAccuracyKNN} for KNN\")\n",
        "print(\"Classification report for KNN validation set:\\n\", X_valReportKNN)\n",
        "\n",
        "print(f\"The validation set had an accuracy of {X_valAccuracyNN} for Neural Network\")\n",
        "print(\"Classification report for Neural Network validation set:\\n\", X_valReportNN)\n",
        "\n",
        "print(f\"The validation set had an accuracy of {X_valAccuracyDT} for Decision Tree\")\n",
        "print(\"Classification report for Decision Tree validation set:\\n\", X_valReportDT)\n",
        "\n",
        "combined_predictions = np.column_stack((X_valPredictionKNN, X_valPredictionNN, X_valPredictionDT))\n",
        "final_predictions = mode(combined_predictions, axis=1).mode.flatten()\n",
        "\n",
        "X_valAccuracyCombined = accuracy_score(y_val, final_predictions)\n",
        "X_valReportCombined = classification_report(y_val, final_predictions, zero_division=1)\n",
        "\n",
        "print(f\"The combined model had an accuracy of {X_valAccuracyCombined}\")\n",
        "print(\"Classification report for the combined model:\\n\", X_valReportCombined)\n",
        "\n",
        "myKNN.fit(trainDataScaled, trainLabels.values.ravel())\n",
        "myNN.fit(trainDataScaled, trainLabels.values.ravel())\n",
        "myDT.fit(trainDataScaled, trainLabels.values.ravel())\n",
        "\n",
        "testDataPredictionKNN = myKNN.predict(testDataScaled)\n",
        "testDataPredictionNN = myNN.predict(testDataScaled)\n",
        "testDataPredictionDT = myDT.predict(testDataScaled)\n",
        "\n",
        "combined_test_predictions = np.column_stack((testDataPredictionKNN, testDataPredictionNN, testDataPredictionDT))\n",
        "final_test_predictions = mode(combined_test_predictions, axis=1).mode.flatten()\n",
        "\n",
        "print(\"\\nPredictions on Test Data from the Combined Model:\\n\", final_test_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXC4dA2lanIO",
        "outputId": "fbed5f69-d9b1-4a3e-8689-08d1414f4be4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values count in train data:\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "dtype: int64\n",
            "The validation set had an accuracy of 0.5714285714285714 for KNN\n",
            "Classification report for KNN validation set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       1.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         7\n",
            "           5       0.67      0.67      0.67       104\n",
            "           6       0.47      0.58      0.52        81\n",
            "           7       0.65      0.39      0.49        28\n",
            "           8       1.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.57       224\n",
            "   macro avg       0.63      0.27      0.28       224\n",
            "weighted avg       0.58      0.57      0.56       224\n",
            "\n",
            "The validation set had an accuracy of 0.5714285714285714 for Neural Network\n",
            "Classification report for Neural Network validation set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       1.00      0.00      0.00         2\n",
            "           4       1.00      0.00      0.00         7\n",
            "           5       0.68      0.74      0.71       104\n",
            "           6       0.46      0.62      0.53        81\n",
            "           7       1.00      0.04      0.07        28\n",
            "           8       1.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.57       224\n",
            "   macro avg       0.86      0.23      0.22       224\n",
            "weighted avg       0.65      0.57      0.53       224\n",
            "\n",
            "The validation set had an accuracy of 0.5758928571428571 for Decision Tree\n",
            "Classification report for Decision Tree validation set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.10      0.14      0.12         7\n",
            "           5       0.73      0.69      0.71       104\n",
            "           6       0.52      0.53      0.52        81\n",
            "           7       0.43      0.46      0.45        28\n",
            "           8       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.58       224\n",
            "   macro avg       0.30      0.31      0.30       224\n",
            "weighted avg       0.59      0.58      0.58       224\n",
            "\n",
            "The combined model had an accuracy of 0.6160714285714286\n",
            "Classification report for the combined model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         7\n",
            "           5       0.71      0.74      0.72       104\n",
            "           6       0.52      0.65      0.58        81\n",
            "           7       0.80      0.29      0.42        28\n",
            "           8       1.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.62       224\n",
            "   macro avg       0.50      0.28      0.29       224\n",
            "weighted avg       0.62      0.62      0.60       224\n",
            "\n",
            "\n",
            "Predictions on Test Data from the Combined Model:\n",
            " [5 5 5 6 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 6 5 5 5 5 6 5 5 5 5 5 5 5 5 5\n",
            " 6 5 5 6 5 5 5 5 5 6 5 6 5 5 5 5 6 6 5 5 5 5 5 5 5 5 6 5 5 6 7 5 5 5 6 5 5\n",
            " 5 5 5 5 6 5 5 5 6 6 7 5 6 5 5 5 5 5 5 6 5 6 6 6 6 5 6 6 7 6 5 6 6 6 7 6 6\n",
            " 5 5 5 5 5 6 6 5 6 7 6 5 6 6 5 6 6 6 6 6 5 6 5 6 6 6 5 6 5 5 6 6 6 7 7 6 6\n",
            " 5 7 5 6 6 6 5 6 6 6 5 6 6 6 5 6 5 5 5 5 5 6 6 5 7 5 5 5 4 5 6 6 6 5 6 5 5\n",
            " 6 6 6 5 5 7 5 5 5 6 6 5 5 5 5 5 5 6 5 6 4 6 5 5 5 5 4 5 5 6 5 5 6 5 6 5 5\n",
            " 5 6 5 5 5 6 5 5 5 6 5 4 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 6 6 6 6 6 6 5 6 5 5\n",
            " 6 5 6 5 6 6 5 6 6 6 6 6 6 5 5 6 5 5 5 7 7 6 6 6 6 5 7 7 6 6 6 5 6 6 5 6 5\n",
            " 6 5 5 5 5 6 5 6 7 7 7 7 7 6 6 7 6 5 5 5 6 6 7 6 5 6 7 7 5 5 5 6 5 5 6 6 5\n",
            " 6 6 7 6 5 7 7 6 4 4 6 5 6 5 5 6 6 6 6 6 5 6 6 6 5 5 5 5 5 6 6 7 5 6 6 6 6\n",
            " 6 5 5 5 6 6 5 5 6 5 5 5 6 5 6 6 5 5 5 6 5 6 7 5 5 5 5 5 6 6 5 6 6 6 5 5 5\n",
            " 5 5 5 5 5 6 6 6 5 5 5 5 6 5 6 6 7 5 5 5 5 5 6 5 6 5 4 6 5 6 5 5 6 5 7 5 4\n",
            " 7 5 5 6 5 6 6 6 7 5 5 5 6 5 5 6 6 6 6 6 6 6 5 6 6 5 5 7 6 5 6 6 6 6 6 5]\n"
          ]
        }
      ]
    }
  ]
}