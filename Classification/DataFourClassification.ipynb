{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.449870</td>\n",
       "      <td>-0.200490</td>\n",
       "      <td>-0.487290</td>\n",
       "      <td>-0.061085</td>\n",
       "      <td>-0.051024</td>\n",
       "      <td>-0.021653</td>\n",
       "      <td>0.307880</td>\n",
       "      <td>-0.057097</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>0.132410</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5912</td>\n",
       "      <td>23.2100</td>\n",
       "      <td>146.23</td>\n",
       "      <td>-178.08</td>\n",
       "      <td>152.01</td>\n",
       "      <td>-129.720</td>\n",
       "      <td>126.480</td>\n",
       "      <td>-147.33</td>\n",
       "      <td>168.65</td>\n",
       "      <td>180.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.528430</td>\n",
       "      <td>-0.259120</td>\n",
       "      <td>-0.425840</td>\n",
       "      <td>-0.061339</td>\n",
       "      <td>-0.075853</td>\n",
       "      <td>-0.027442</td>\n",
       "      <td>0.301660</td>\n",
       "      <td>-0.064007</td>\n",
       "      <td>-0.042905</td>\n",
       "      <td>0.330570</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7736</td>\n",
       "      <td>-4.6825</td>\n",
       "      <td>103.02</td>\n",
       "      <td>-182.73</td>\n",
       "      <td>168.97</td>\n",
       "      <td>-151.290</td>\n",
       "      <td>124.890</td>\n",
       "      <td>-118.42</td>\n",
       "      <td>125.41</td>\n",
       "      <td>203.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.498230</td>\n",
       "      <td>-0.263460</td>\n",
       "      <td>-0.406830</td>\n",
       "      <td>-0.050683</td>\n",
       "      <td>-0.066742</td>\n",
       "      <td>-0.024397</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>-0.130610</td>\n",
       "      <td>-0.105670</td>\n",
       "      <td>0.285960</td>\n",
       "      <td>...</td>\n",
       "      <td>38.8230</td>\n",
       "      <td>-53.3400</td>\n",
       "      <td>161.33</td>\n",
       "      <td>-180.05</td>\n",
       "      <td>151.52</td>\n",
       "      <td>-127.850</td>\n",
       "      <td>117.960</td>\n",
       "      <td>-125.76</td>\n",
       "      <td>139.76</td>\n",
       "      <td>193.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.424050</td>\n",
       "      <td>-0.183920</td>\n",
       "      <td>-0.337610</td>\n",
       "      <td>-0.035511</td>\n",
       "      <td>-0.048362</td>\n",
       "      <td>-0.008383</td>\n",
       "      <td>0.234870</td>\n",
       "      <td>-0.197570</td>\n",
       "      <td>-0.075233</td>\n",
       "      <td>0.133230</td>\n",
       "      <td>...</td>\n",
       "      <td>81.5990</td>\n",
       "      <td>-93.0770</td>\n",
       "      <td>145.09</td>\n",
       "      <td>172.44</td>\n",
       "      <td>-196.78</td>\n",
       "      <td>-135.790</td>\n",
       "      <td>124.880</td>\n",
       "      <td>-134.61</td>\n",
       "      <td>145.45</td>\n",
       "      <td>194.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.214870</td>\n",
       "      <td>-0.245080</td>\n",
       "      <td>-0.252040</td>\n",
       "      <td>-0.111790</td>\n",
       "      <td>-0.045751</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.216660</td>\n",
       "      <td>-0.216510</td>\n",
       "      <td>-0.085224</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.4200</td>\n",
       "      <td>-149.6900</td>\n",
       "      <td>154.25</td>\n",
       "      <td>-168.03</td>\n",
       "      <td>172.94</td>\n",
       "      <td>161.300</td>\n",
       "      <td>-164.670</td>\n",
       "      <td>179.68</td>\n",
       "      <td>-194.52</td>\n",
       "      <td>192.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>-0.055413</td>\n",
       "      <td>-0.028708</td>\n",
       "      <td>-0.050070</td>\n",
       "      <td>-0.092470</td>\n",
       "      <td>-0.087130</td>\n",
       "      <td>-0.037582</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>-0.384240</td>\n",
       "      <td>-0.281220</td>\n",
       "      <td>0.051134</td>\n",
       "      <td>...</td>\n",
       "      <td>-129.1200</td>\n",
       "      <td>-183.1200</td>\n",
       "      <td>172.83</td>\n",
       "      <td>199.73</td>\n",
       "      <td>-226.64</td>\n",
       "      <td>158.590</td>\n",
       "      <td>-97.553</td>\n",
       "      <td>127.84</td>\n",
       "      <td>-185.16</td>\n",
       "      <td>203.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>-0.044765</td>\n",
       "      <td>-0.028708</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>-0.034470</td>\n",
       "      <td>-0.014174</td>\n",
       "      <td>-0.037582</td>\n",
       "      <td>0.043463</td>\n",
       "      <td>-0.386750</td>\n",
       "      <td>-0.293210</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>...</td>\n",
       "      <td>190.4200</td>\n",
       "      <td>-171.6100</td>\n",
       "      <td>170.07</td>\n",
       "      <td>150.35</td>\n",
       "      <td>-188.96</td>\n",
       "      <td>214.620</td>\n",
       "      <td>-172.170</td>\n",
       "      <td>168.19</td>\n",
       "      <td>-190.24</td>\n",
       "      <td>197.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>-0.053542</td>\n",
       "      <td>-0.089060</td>\n",
       "      <td>-0.090247</td>\n",
       "      <td>-0.172140</td>\n",
       "      <td>-0.162600</td>\n",
       "      <td>-0.081363</td>\n",
       "      <td>0.049554</td>\n",
       "      <td>-0.413170</td>\n",
       "      <td>-0.293190</td>\n",
       "      <td>0.121840</td>\n",
       "      <td>...</td>\n",
       "      <td>168.5300</td>\n",
       "      <td>-170.9900</td>\n",
       "      <td>181.53</td>\n",
       "      <td>154.11</td>\n",
       "      <td>-175.15</td>\n",
       "      <td>179.540</td>\n",
       "      <td>-172.070</td>\n",
       "      <td>204.38</td>\n",
       "      <td>-203.96</td>\n",
       "      <td>189.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>-0.104460</td>\n",
       "      <td>-0.231630</td>\n",
       "      <td>-0.228320</td>\n",
       "      <td>-0.260140</td>\n",
       "      <td>-0.243730</td>\n",
       "      <td>-0.184850</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>-0.424890</td>\n",
       "      <td>-0.290430</td>\n",
       "      <td>0.226890</td>\n",
       "      <td>...</td>\n",
       "      <td>180.4800</td>\n",
       "      <td>-212.7500</td>\n",
       "      <td>182.87</td>\n",
       "      <td>176.90</td>\n",
       "      <td>-216.82</td>\n",
       "      <td>-85.159</td>\n",
       "      <td>131.410</td>\n",
       "      <td>135.09</td>\n",
       "      <td>-138.10</td>\n",
       "      <td>179.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>-0.046330</td>\n",
       "      <td>-0.074681</td>\n",
       "      <td>-0.075151</td>\n",
       "      <td>-0.120140</td>\n",
       "      <td>-0.146250</td>\n",
       "      <td>-0.047532</td>\n",
       "      <td>0.046695</td>\n",
       "      <td>-0.395340</td>\n",
       "      <td>-0.314190</td>\n",
       "      <td>0.076395</td>\n",
       "      <td>...</td>\n",
       "      <td>204.7200</td>\n",
       "      <td>-191.8900</td>\n",
       "      <td>176.03</td>\n",
       "      <td>170.51</td>\n",
       "      <td>-189.96</td>\n",
       "      <td>-105.010</td>\n",
       "      <td>138.320</td>\n",
       "      <td>150.32</td>\n",
       "      <td>-175.81</td>\n",
       "      <td>193.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2547 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.449870 -0.200490 -0.487290 -0.061085 -0.051024 -0.021653  0.307880   \n",
       "1    -0.528430 -0.259120 -0.425840 -0.061339 -0.075853 -0.027442  0.301660   \n",
       "2    -0.498230 -0.263460 -0.406830 -0.050683 -0.066742 -0.024397  0.275000   \n",
       "3    -0.424050 -0.183920 -0.337610 -0.035511 -0.048362 -0.008383  0.234870   \n",
       "4    -0.214870 -0.245080 -0.252040 -0.111790 -0.045751 -0.035225  0.216660   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2542 -0.055413 -0.028708 -0.050070 -0.092470 -0.087130 -0.037582  0.044267   \n",
       "2543 -0.044765 -0.028708 -0.020877 -0.034470 -0.014174 -0.037582  0.043463   \n",
       "2544 -0.053542 -0.089060 -0.090247 -0.172140 -0.162600 -0.081363  0.049554   \n",
       "2545 -0.104460 -0.231630 -0.228320 -0.260140 -0.243730 -0.184850  0.055340   \n",
       "2546 -0.046330 -0.074681 -0.075151 -0.120140 -0.146250 -0.047532  0.046695   \n",
       "\n",
       "           7         8         9    ...       102       103     104     105  \\\n",
       "0    -0.057097 -0.015610  0.132410  ...    4.5912   23.2100  146.23 -178.08   \n",
       "1    -0.064007 -0.042905  0.330570  ...    9.7736   -4.6825  103.02 -182.73   \n",
       "2    -0.130610 -0.105670  0.285960  ...   38.8230  -53.3400  161.33 -180.05   \n",
       "3    -0.197570 -0.075233  0.133230  ...   81.5990  -93.0770  145.09  172.44   \n",
       "4    -0.216510 -0.085224  0.331200  ... -178.4200 -149.6900  154.25 -168.03   \n",
       "...        ...       ...       ...  ...       ...       ...     ...     ...   \n",
       "2542 -0.384240 -0.281220  0.051134  ... -129.1200 -183.1200  172.83  199.73   \n",
       "2543 -0.386750 -0.293210  0.026051  ...  190.4200 -171.6100  170.07  150.35   \n",
       "2544 -0.413170 -0.293190  0.121840  ...  168.5300 -170.9900  181.53  154.11   \n",
       "2545 -0.424890 -0.290430  0.226890  ...  180.4800 -212.7500  182.87  176.90   \n",
       "2546 -0.395340 -0.314190  0.076395  ...  204.7200 -191.8900  176.03  170.51   \n",
       "\n",
       "         106      107      108     109     110     111  \n",
       "0     152.01 -129.720  126.480 -147.33  168.65  180.33  \n",
       "1     168.97 -151.290  124.890 -118.42  125.41  203.31  \n",
       "2     151.52 -127.850  117.960 -125.76  139.76  193.23  \n",
       "3    -196.78 -135.790  124.880 -134.61  145.45  194.52  \n",
       "4     172.94  161.300 -164.670  179.68 -194.52  192.15  \n",
       "...      ...      ...      ...     ...     ...     ...  \n",
       "2542 -226.64  158.590  -97.553  127.84 -185.16  203.81  \n",
       "2543 -188.96  214.620 -172.170  168.19 -190.24  197.18  \n",
       "2544 -175.15  179.540 -172.070  204.38 -203.96  189.57  \n",
       "2545 -216.82  -85.159  131.410  135.09 -138.10  179.36  \n",
       "2546 -189.96 -105.010  138.320  150.32 -175.81  193.26  \n",
       "\n",
       "[2547 rows x 112 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "TrainData 4 contains 112 features with 2547 samples. Testdata4 contains 112 features with 1092 samples. There are 9 classes in this dataset.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "trainData = pd.read_csv('../DataFiles/TrainData4.txt', sep='\\\\s+', header=None)\n",
    "trainLabels = pd.read_csv('../DataFiles/TrainLabel4.txt', sep='\\\\s+', header=None)\n",
    "testData = pd.read_csv('../DataFiles/TestData4.txt', sep='\\\\s+', header=None)\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in trainData: 0\n",
      "Missing values in testData: 0\n"
     ]
    }
   ],
   "source": [
    "trainData.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
    "testData.replace(1.00000000000000e+99, np.nan, inplace=True)\n",
    "\n",
    "# There are no missing values in any of the txt files\n",
    "print(\"Missing values in trainData:\", trainData.isnull().sum().sum())\n",
    "print(\"Missing values in testData:\", testData.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.90621523, -1.51505757, -5.77090401, ..., -0.74893122,\n",
       "         0.94272041,  1.05676578],\n",
       "       [-5.98790689, -2.33139224, -4.85284398, ..., -0.57140259,\n",
       "         0.69268576,  1.18668064],\n",
       "       [-5.57208347, -2.39182022, -4.56883549, ..., -0.61647558,\n",
       "         0.77566442,  1.12969449],\n",
       "       ...,\n",
       "       [ 0.55082005,  0.03643778,  0.16089926, ...,  1.41082639,\n",
       "        -1.21189138,  1.10900309],\n",
       "       [-0.15026925, -1.94863529, -1.9019047 , ...,  0.98533492,\n",
       "        -0.83105691,  1.051282  ],\n",
       "       [ 0.65012199,  0.23664375,  0.38643277, ...,  1.0788583 ,\n",
       "        -1.04911442,  1.12986409]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScaler = StandardScaler()         \n",
    "\n",
    "trainDataScaled = myScaler.fit_transform(trainData)\n",
    "testDataScaled = myScaler.transform(testData)\n",
    "trainDataScaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Recall: TrainData 4 contains 112 features with 2547 samples. Testdata4 contains 112 features with 1092 samples. There are 9 classes in this dataset.\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainDataScaled, trainLabels, shuffle=True, test_size=0.2, random_state=50)\n",
    "\n",
    "mySVM = SVC(kernel='linear')                        # AC1103 -- This is for feature selection which utlizes RFE(wrapper method) with Support Vector Machine Classification\n",
    "myRFE = RFE(estimator=mySVM, n_features_to_select=65, step=10)\n",
    "myRFE.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# AC1103 -- After RFE, 65 features are selected and then the training and validation sets are transformed to have those 65 models, now the data can be classified using 'rbf' kernel\n",
    "X_trainRFE = myRFE.transform(X_train)\n",
    "X_valRFE = myRFE.transform(X_val)\n",
    "\n",
    "\n",
    "#AC1103 -- This cell is just feature selecting, there is no classification happening --> went from 112 features to 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation set had an accuracy of 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVC(C=3)\n",
    "\n",
    "mySVM.fit(X_trainRFE, y_train.values.ravel())\n",
    "X_valPrediction = mySVM.predict(X_valRFE)\n",
    "\n",
    "X_valAccuracy = accuracy_score(y_val, X_valPrediction)\n",
    "X_valReport = classification_report(y_val, X_valPrediction)\n",
    "\n",
    "print(f\"The validation set had an accuracy of {X_valAccuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainData after RFE: (2547, 65)\n",
      "Shape of testData after RFE: (1092, 65)\n",
      "\n",
      "Predictions on Test Data: [1 1 1 ... 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "fullRFE = RFE(estimator=SVC(kernel='linear'), n_features_to_select=65, step=10)         # AC1103 -- Applying RFE to the whole training set\n",
    "\n",
    "fullRFE.fit(trainDataScaled, trainLabels.values.ravel())\n",
    "trainDataRFE = fullRFE.transform(trainDataScaled)\n",
    "testDataRFE = fullRFE.transform(testDataScaled)\n",
    "\n",
    "print(\"Shape of trainData after RFE:\", trainDataRFE.shape)\n",
    "print(\"Shape of testData after RFE:\", testDataRFE.shape)\n",
    "\n",
    "\n",
    "mySVM.fit(trainDataRFE, trainLabels.values.ravel())\n",
    "testDataPredictions = mySVM.predict(testDataRFE)\n",
    "\n",
    "print(\"\\nPredictions on Test Data:\", testDataPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to C:\\Users\\alexs\\OneDrive\\Desktop\\PythonProjects\\CSC4850_Project\\PredictionResults\\CastroClassification4.txt.\n"
     ]
    }
   ],
   "source": [
    "output_dir = r\"C:\\Users\\alexs\\OneDrive\\Desktop\\PythonProjects\\CSC4850_Project\\PredictionResults\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, \"CastroClassification4.txt\")\n",
    "np.savetxt(output_path, testDataPredictions, fmt='%d')\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Predictions saved to {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
